{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "94f65efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e643c5",
   "metadata": {},
   "source": [
    "## 模型准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cde8fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA_VISIBLE_DEVICES=0\n",
    "# python -m vllm.entrypoints.openai.api_server --served-model-name Qwen2.5-72B-Instruct --model /gemini/data-1/Qwen2.5-72B-Instruct-GPTQ-Int4/ --port 8000 --tensor-parallel-size 2\n",
    "# python -m vllm.entrypoints.openai.api_server --served-model-name Qwen2.5-7B-Instruct --model /gemini/data-1/Qwen2.5-7B-Instruct/ --port 8000 --tensor-parallel-size 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cca9c21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入部署好的模型\n",
    "client = OpenAI(\n",
    "    api_key=\"EMPTY\",\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    ")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5640a854",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb7ccc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取原始数据并处理成需要的格式\n",
    "def dataset_jsonl_transfer(origin_path, new_path=None):\n",
    "    \"\"\"\n",
    "    将原始数据集转换为大模型微调所需数据格式的新数据集\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    Real_outputs = []\n",
    "\n",
    "    # 读取旧的JSONL文件\n",
    "    with open(origin_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            # 解析每一行的json数据\n",
    "            data = json.loads(line)\n",
    "            input_text = data[\"text\"]\n",
    "            entities = data[\"entities\"]\n",
    "            match_names = [\"地点\", \"人名\", \"地理实体\", \"组织\"]\n",
    "            \n",
    "            entity_sentence = \"\"\n",
    "            for entity in entities:\n",
    "                entity_json = dict(entity)\n",
    "                entity_text = entity_json[\"entity_text\"]\n",
    "                entity_names = entity_json[\"entity_names\"]\n",
    "                for name in entity_names:\n",
    "                    if name in match_names:\n",
    "                        entity_label = name\n",
    "                        break\n",
    "                \n",
    "                entity_sentence += f\"\"\"{{\"entity_text\": \"{entity_text}\", \"entity_label\": \"{entity_label}\"}}\"\"\"\n",
    "            \n",
    "            if entity_sentence == \"\":\n",
    "                entity_sentence = \"没有找到任何实体\"\n",
    "                \n",
    "            \n",
    "            message = [\n",
    "                {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": \"\"\"你是一个文本实体识别领域的专家，你需要从给定的句子中提取 地点; 人名; 地理实体; 组织 实体. 以 json 格式输出, 如 {\"entity_text\": \"南京\", \"entity_label\": \"地理实体\"} 注意: 1. 输出的每一行都必须是正确的 json 字符串. 2. 找不到任何实体时, 输出\"没有找到任何实体\". 需要你分析的文本为：\"\"\" + input_text}\n",
    "            ]\n",
    "            \n",
    "            messages.append(message)\n",
    "            Real_outputs.append(entity_sentence)\n",
    "            \n",
    "        return messages,Real_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa7ae3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取输入数据\n",
    "messages,Real_outputs = dataset_jsonl_transfer(\"../OriginalData/chinese_ner_sft/ccfbdci.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e54c7c",
   "metadata": {},
   "source": [
    "## 模型推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "599ec1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Outputs = []\n",
    "for message in messages[:10]:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"Qwen2.5-7B-Instruct\",\n",
    "        messages=message,\n",
    "        stream=False,\n",
    "        temperature=0.01,\n",
    "        max_tokens=3000,\n",
    "    )\n",
    "    Outputs.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "99418d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"entity_text\": \"阿美达\", \"entity_label\": \"人名\"}\\n{\"entity_text\": \"基督教传教士\", \"entity_label\": \"组织\"}'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Outputs[1].choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd845d1",
   "metadata": {},
   "source": [
    "## 结果对比分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "03437ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prompt1 = \"\"\"对于一个实体识别任务，我现在将给你大语言模型进行识别后的模型输出，以及该实体识别任务的真实结果，你需要对模型输出的质量进行评价。\n",
    "## 评价的标准如下：\n",
    "- 标准A：你需要针对模型输出的实体识别结果，如果该结果存在于真实结果中，请你识别结果中给出的\"entity_label\"是否准确，准确的个数越多，证明识别记过越好。\n",
    "- 标准B：你需要统计模型输出的结果中，存在于真实结果的数量，其中模型输出的实体识别结果中，存在于真实结果的比重越大，则说明识别效果越好。\n",
    "- 标准C：你需要识别模型输出结果和真是结果的差异，其中模型输出结果和真实结果重合度越高，证明识别效果越好。\n",
    "## 计分标准如下\n",
    "- 根据我给你的标准A、B、C，每个标准从不好到好分为[1,2,3,4,5,6,7,8,9,10]共10个得分等级，你需要先给出每个标准下的得分。\n",
    "- 根据每个标准下的得分计算出一个平均分作为你最终的得分输出。\n",
    "## 输出格式\n",
    "- 你只需要输出最终的得分即可。\n",
    "- 你的输出格式为：【最终得分：XX】\n",
    "# 待分析数据\n",
    "- 模型输出：{}\n",
    "- 真实结果：{}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "914b806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_outcome(Outputs, Real_outputs):\n",
    "    # 得分\n",
    "    scores = []\n",
    "    # 逐条分析\n",
    "    for Output, Real_outputs in tqdm(zip(Outputs, Real_outputs)):\n",
    "        prompt = Prompt1.format(Output.choices[0].message.content, Real_outputs)\n",
    "        message = [\n",
    "            {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "        # 获得结果\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"Qwen2.5-7B-Instruct\",\n",
    "            messages=message,\n",
    "            stream=False,\n",
    "            temperature=0.01,\n",
    "            max_tokens=3000,\n",
    "        )\n",
    "        # 抽取得分\n",
    "        score = 0\n",
    "        try:\n",
    "            score = int(response.choices[0].message.content.split(\"【最终得分：\")[1].split(\"】\")[0])\n",
    "        except:\n",
    "            score = 0\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c38ee8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:02,  3.84it/s]\n"
     ]
    }
   ],
   "source": [
    "scores = analysis_outcome(Outputs, Real_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ebbfcbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n"
     ]
    }
   ],
   "source": [
    "# 统计不合理数据的数量\n",
    "print(np.mean(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
