{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93a32859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge_chinese import Rouge\n",
    "import jieba\n",
    "import json\n",
    "from bert_score import score\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import AutoTokenizer\n",
    "from GeneralRequestProcessor import GeneralRequestProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20f0b60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取和保存数据的函数\n",
    "def read_json_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误：找不到文件 {file_path}。请检查文件路径是否正确。\")\n",
    "        return None\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"错误：无法解码文件 {file_path} 中的JSON数据。请确保这是一个有效的JSON文件。\")\n",
    "        return None\n",
    "    \n",
    "def save_to_json_file(data, file_path):\n",
    "    try:\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "        print(f\"数据成功保存到 {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"保存文件时发生错误: {e}\")   \n",
    "## 获取8-shot\n",
    "def make_shot(origin_data=None):\n",
    "    shot_8 = \"\"\n",
    "    for index, single_data in enumerate(origin_data[4492:4500]):\n",
    "        shot_ = f\"【**案例{index}**：\\n{single_data['conversations'][1]['value']}\\n】\"\n",
    "        shot_8 += shot_\n",
    "    return shot_8\n",
    "\n",
    "# 读取原始数据并处理成需要的格式\n",
    "def make_messages(origin_data=None):\n",
    "    \"\"\"\n",
    "    将原始数据集转换为大模型微调所需数据格式的新数据集\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    Real_outputs = []\n",
    "    shot_8 = make_shot(origin_data)\n",
    "    for index, single_data in enumerate(origin_data):\n",
    "        random_number = random.randint(0, 9)\n",
    "        message = [\n",
    "            {\"role\": \"system\", \"content\": \"\"},\n",
    "#             {\"role\": \"user\", \"content\": single_data['conversations'][0]['value']}\n",
    "            {\"role\": \"user\", \"content\": \"{}\\n-{},以下是供你参考的人文社科领域学术文本摘要案例\\n{}\".format(head_template_COT3, single_data['conversations'][0]['value'], shot_8)}\n",
    "        ]\n",
    "        messages.append([message,index])\n",
    "        Real_outputs.append(single_data['conversations'][1]['value'])\n",
    "            \n",
    "    return messages,Real_outputs\n",
    "\n",
    "def ChatCompletions(message):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"MyModel\",\n",
    "        messages=message,\n",
    "        stream=False,\n",
    "        temperature=0.01,\n",
    "        max_tokens=5000,\n",
    "    )\n",
    "    return response.choices[0].message.content        \n",
    "\n",
    "def process_cot(abstract, model):\n",
    "    abstract_COT = []\n",
    "    if model == 'qwen':\n",
    "        count = []\n",
    "        for idx, value in enumerate(abstract):\n",
    "            try:\n",
    "                Model_output_COT = value.split('<最终摘要>')[1].strip('\\n')\n",
    "            except:\n",
    "                count.append(idx)\n",
    "                Model_output_COT = value\n",
    "            abstract_COT.append(Model_output_COT)\n",
    "        print(f\"本次存在问题的id为{count}\", '\\n', '------------------------------')\n",
    "    elif model == 'llama':\n",
    "        count = []\n",
    "        for idx, value in enumerate(abstract):\n",
    "            try:\n",
    "                Model_output_COT = value.split('最终摘要')[1].strip('\\n')\n",
    "            except:\n",
    "                count.append(idx)\n",
    "                Model_output_COT = value.split('\\n')[-1]\n",
    "            abstract_COT.append(Model_output_COT)\n",
    "        print(f\"本次存在问题的id为{count}\", '\\n', '------------------------------')\n",
    "    else:\n",
    "        print(\"输入有误\")\n",
    "    return abstract_COT\n",
    "\n",
    "def process_deep(abstract):\n",
    "    abstract_new = []\n",
    "    idx_list = []\n",
    "    count = []\n",
    "    for idx, value in enumerate(abstract):\n",
    "        try:\n",
    "            Model_output_deepseek = value.split('</think>')[1].strip('\\n')\n",
    "        except:\n",
    "            Model_output_deepseek = \"文本生成失败\"\n",
    "        # 测试长度\n",
    "        encoded_text = tokenizer.encode(value)\n",
    "        if len(encoded_text) > 3000:\n",
    "            Model_output_deepseek = \"文本生成失败\"\n",
    "            count.append(idx)\n",
    "        else:\n",
    "            idx_list.append(idx)\n",
    "        abstract_new.append(Model_output_deepseek)\n",
    "    print(f\"本次存在问题的id为{count}\", '\\n', '------------------------------')\n",
    "    return abstract_new, idx_list\n",
    "\n",
    "head_template = [\n",
    "    \"请你根据给出的学术全文本内容，生成关于该文本的摘要。\",\n",
    "    \"请根据提供的学术文本内容，生成一个该文本的摘要。\",\n",
    "    \"请根据给定的学术全文，撰写一个简要总结。\",\n",
    "    \"请根据所提供的学术文章内容，生成一个概述。\",\n",
    "    \"你需要阅读以下学术文本，并根据其内容编写摘要\",\n",
    "    \"根据给出的学术材料，请你整理出一份摘要。\",\n",
    "    \"请将下面的学术文本内容总结成一个简短的摘要。\",\n",
    "    \"请从提供的学术文本中提炼出摘要内容。\",\n",
    "    \"请根据以下学术文本写一段简短的总结。\",\n",
    "    \"请基于下列学术全文，提炼并生成相关摘要。\"\n",
    "]\n",
    "head_template_COT = \"\"\"\n",
    "下面，我将会给你一份学术文本内容，你需要分析给出的内容，编写关于该学术文本的摘要。除去学术文本，我还会给你其他学术文本的摘要作为参考案例\n",
    "## 编写摘要要求\n",
    "- 首先你需要分析我给你的学术文本摘要案例，案例总共8个，你需要分析每一份摘要案例的行文特点和语言特征，作为你生成摘要的支撑。\n",
    "- 然后你需要分析我所给你的学术文本主要讲述的核心内容，涉及的实验对象等学术信息，并分析你认为的每一个段落的关键语句。\n",
    "- 最后，你需要根据你的分析，结合你从我所提供的摘要的行文特点和语言特征，编写一份我所给你的学术文本内容的摘要。\n",
    "## 输出格式\n",
    "- 你输出数据的格式应严格为：<所给摘要特征总结>xxxxx\\n<学术文本内容分析>xxxxx\\n<最终摘要>xxxxx\n",
    "\"\"\"\n",
    "\n",
    "head_template_COT2 = \"\"\"\n",
    "下面，我将会给你一份学术文本内容，你需要分析给出的内容，编写关于该学术文本的摘要。除去学术文本，我还会给你其他学术文本的摘要作为参考案例\n",
    "## 编写摘要要求\n",
    "- 首先你需要分析我给你的学术文本摘要案例，案例总共8个，你需要分析每一份摘要案例的行文特点和语言特征，作为你生成摘要的支撑。\n",
    "- 然后你需要分析我所给你的学术文本主要讲述的核心内容，涉及的实验对象等学术信息，并分析你认为的每一个段落的关键语句。\n",
    "- 最后，你需要根据你的分析，结合你从我所提供的摘要的行文特点和语言特征，编写一份我所给你的学术文本内容的摘要。\n",
    "## 输出格式\n",
    "- 你的最终输出只需要给出你的摘要即可，不用给出其他内容！\n",
    "\"\"\"\n",
    "\n",
    "head_template_COT3 = \"\"\"\n",
    "下面，我会先给你一份人文社科学术文本，你需要总结该文本摘要。此外，我还会给你8个摘要案例作为编写学术文本的参考，编写中需要注意的点如下：\n",
    "## 所给摘要特征总结要求\n",
    "- 你需要分析我给你的学术文本摘要案例，案例总共8个，你需要分析每一份摘要案例的行文特点和语言特征，作为你生成摘要的支撑。\n",
    "- 你要根据你对案例摘要分析的内容，在<所给摘要特征总结>模块给出人文社科领域学术文本摘要的行文特点和语言特征，为之后修改摘要提供依据。\n",
    "## 学术文本内容分析要求\n",
    "- 人文社科领域摘要的重点在于背景描述和本文论点的结合。\n",
    "- 首先你需要识别出本文的研究对象，并在<学术文本内容分析>模块中以【研究对象：xxxx】的格式给出。\n",
    "- 其次你需要识别出本文的研究背景，并在<学术文本内容分析>模块中以【研究背景：xxxx】的格式给出。\n",
    "- 然后你需要以文章段落为单位进行分析，找出文中关于研究对象的论述，并在<学术文本内容分析>模块中以【论述x：xxxx】的格式给出。\n",
    "- 你需要分析不同论述之间是并列、递进亦或对比等关系，并在<学术文本内容分析>模块中按照论述关系三元组【论述m，关系，论述n】的格式给出。\n",
    "- 最后你要根据总结的论述关系三元组，分析出本文论述的核心论点，并在<学术文本内容分析>模块中以【核心论点：xxxx】的格式给出\n",
    "## 初步摘要的编写\n",
    "- 你要围绕<学术文本内容分析>模块中给出的“研究对象”、“研究背景”以及“核心论点”部分内容编写初步摘要，并在<初步摘要>模块给出。\n",
    "## 摘要审改的编写\n",
    "- 根据<初步摘要>模块的初步摘要，结合<所给摘要特征总结>模块中人文社科领域学术文本的行文特点和语言特征，以及你得到的8个案例，对初步摘要进行修改。\n",
    "- 你需要比对初步摘要同案例摘要在语言特征方面的区别，并在<摘要审改>模块中以【区别x:xxxxx】形式给出。\n",
    "- 你需要根据你所罗列的区别信息，在<摘要审改>模块中给出摘要修改的思路。\n",
    "## 最终摘要的编写\n",
    "- 根据在<摘要审改>模块中得到的思路，对<初步摘要>模块中的摘要内容进行修改，力求修改后的语言和结构特征同真实摘要一致。\n",
    "- 真实摘要中较少使用（首先、其次、再次）这种前后顺序的连接词，因此在最终摘要编写过程中要注意该语言表达特点。\n",
    "- 注意最终摘要中的组织语句主语、谓语宾语等结构的语言表达习惯要同真实摘要相一致。在<最终摘要>模块中给出你所转写的最终摘要。\n",
    "## 输出格式\n",
    "- 你输出数据的格式应严格为：<所给摘要特征总结>xxxxx\\n<学术文本内容分析>xxxxx\\n<初步摘要>xxxxx\\n<摘要审改>xxxxx\\n<最终摘要>xxxxx\n",
    "- <最终摘要>模块仅需要给出你修改好的最终摘要，不要再输出其他的内容！\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd45a4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('/gemini/data-2/DeepSeek-R1-Distill-llama-8B/')\n",
    "# 使用函数读取JSON文件\n",
    "file_path = '/gemini/code/Abstract_extract/ProcessedData/rdfybk/train_data_abstract_mulIns_small.json'  # 将这里的文件路径替换为你自己的JSON文件路径\n",
    "train_test_data = read_json_file(file_path)\n",
    "# 获取输入数据\n",
    "messages,Real_outputs = make_messages(train_test_data)\n",
    "\n",
    "# 读取所有的摘要\n",
    "abstract1 = read_json_file(\"/gemini/code/Abstract_extract/ProcessedData/rdfybk/Model_outputs_7B.json\")\n",
    "abstract2 = read_json_file(\"/gemini/code/Abstract_extract/ProcessedData/rdfybk/Model_outputs_7B_cot.json\")\n",
    "abstract3 = read_json_file(\"/gemini/code/Abstract_extract/ProcessedData/rdfybk/Model_outputs_7B_1.2.json\")\n",
    "abstract4 = read_json_file(\"/gemini/code/Abstract_extract/ProcessedData/rdfybk/Model_outputs_8B.json\")\n",
    "abstract5 = read_json_file(\"/gemini/code/Abstract_extract/ProcessedData/rdfybk/Model_outputs_8B_cot2.json\")\n",
    "abstract6 = read_json_file(\"/gemini/code/Abstract_extract/ProcessedData/rdfybk/Model_outputs_8B_1.4.json\")\n",
    "abstract7 = read_json_file(\"/gemini/code/Abstract_extract/ProcessedData/rdfybk/deepseek_outputs_8B.json\")\n",
    "abstract8 = read_json_file(\"/gemini/code/Abstract_extract/ProcessedData/rdfybk/deepseek_outputs_8B_cot2.json\")\n",
    "abstract9 = read_json_file(\"/gemini/code/Abstract_extract/ProcessedData/rdfybk/deepseek_outputs_7B.json\")\n",
    "abstract10 = read_json_file(\"/gemini/code/Abstract_extract/ProcessedData/rdfybk/deepseek_outputs_7B_cot.json\")\n",
    "# 新补充的实验\n",
    "abstract11 = read_json_file(\"/gemini/code/Abstract_extract/ProcessedData/rdfybk/Model_outputs_7B_cot_plus2.json\")\n",
    "abstract12 = read_json_file(\"/gemini/code/Abstract_extract/ProcessedData/rdfybk/Model_outputs_7B_2.1.json\")\n",
    "abstract13 = read_json_file(\"/gemini/code/Abstract_extract/ProcessedData/rdfybk/Model_outputs_8B_cot_plus.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "980fac10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本次存在问题的id为[21, 26, 141, 229, 232, 239, 270, 335, 357, 497] \n",
      " ------------------------------\n",
      "本次存在问题的id为[0, 40, 62, 81, 83, 103, 178, 191, 195, 219, 223, 225, 361, 371, 387, 395, 412, 436, 452, 469, 477, 487, 489, 497, 499] \n",
      " ------------------------------\n",
      "本次存在问题的id为[21, 25, 26, 33, 36, 42, 106, 126, 128, 135, 141, 145, 155, 169, 198, 205, 215, 224, 229, 232, 239, 266, 270, 271, 295, 298, 320, 333, 335, 367, 385, 420, 443, 469, 477, 489, 497] \n",
      " ------------------------------\n",
      "本次存在问题的id为[2, 35, 83, 169, 229, 464, 469, 476, 482, 488, 496, 497, 499] \n",
      " ------------------------------\n",
      "本次存在问题的id为[357] \n",
      " ------------------------------\n",
      "本次存在问题的id为[36, 139, 486, 497] \n",
      " ------------------------------\n",
      "本次存在问题的id为[] \n",
      " ------------------------------\n",
      "本次存在问题的id为[17, 65, 120, 136, 211, 213, 273, 277, 328, 331, 369, 378, 390, 407, 409, 466, 497] \n",
      " ------------------------------\n",
      "本次存在问题的id为[75, 91, 153, 157, 186, 187, 229, 271, 372, 407, 409, 427, 470, 478] \n",
      " ------------------------------\n"
     ]
    }
   ],
   "source": [
    "abstract2_COT = process_cot(abstract2, 'qwen')\n",
    "abstract5_COT = process_cot(abstract5, 'llama')\n",
    "abstract7_new, idx_list = process_deep(abstract7)\n",
    "abstract8_new, idx_list = process_deep(abstract8)\n",
    "abstract9_new, idx_list = process_deep(abstract9)\n",
    "abstract10_new, idx_list = process_deep(abstract10)\n",
    "abstract11_COT = process_cot(abstract11, 'qwen')\n",
    "abstract12_COT = process_cot(abstract12, 'qwen')\n",
    "abstract13_COT = process_cot(abstract13, 'llama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "05d0ff7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“道德是被感染的，不是被教导的”，这不仅是中国德育教育界的认知，也是加拿大高校的做法。在倡导多元文化并存的社会里，加拿大高校并不要求教师对学生强行灌输道德准则，也不专门开设道德教育课程，而是采取全方位的道德教育方式，创造各种环境，让学生在潜移默化中受到教育，这对我国的德育教育有一定的启示。'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Real_outputs[4505]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4e19636e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'本文探讨了加拿大高校道德教育的特点及其对我国高校德育教育的启示。加拿大高校没有专门的道德教育课程，而是通过普通课程、学生服务、心理咨询、活动开展和环境营造等多种方式渗透道德教育。文章总结了五点启示：一是明确德育教育的基本任务，坚持培养具有国家意志和民族精神人才的目标；二是坚持以学生为本，注重学生的主体性；三是适应社会发展需要，实现德育教育形式的网络化和实践化；四是注重大德育环境的营造，重视渗透性德育的作用；五是强调社会各方面参与学校的德育教育，引导学生关注社会，强化道德实践。这些做法有助于提高德育教育的针对性和实效性。'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract1[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0637c851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'本文探讨了加拿大高校道德教育的特点及其对我国高校德育教育的启示。加拿大高校通过课程教育、学生服务、心理咨询、活动开展和环境营造等多种方式实施道德教育。这些做法强调明确德育任务、坚持以学生为本、实现德育形式的网络化和实践化、营造大德育环境。文章指出，我国高校应借鉴这些做法，明确德育目标，坚持以学生为中心，实现德育教育的网络化和实践化，营造良好的德育环境，以提高德育教育的针对性和实效性。'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract2_COT[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "627e3cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'加拿大高校通过课程教育、为学生服务、心理咨询、开展各种活动和营造德育大环境，成功地实现了道德教育的目标。这些经验启示我国高校应明确德育教育的基本任务，坚持以学生为本的理念，适应社会发展需要，注重大德育环境的营造，从而提高德育教育的针对性和实效性。'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract11_COT[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "59c6a866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'加拿大是一个典型的移民国家，也是一个倡导并践行多元文化的国家。在加拿大的高等教育系统中，从表面上看，它没有专设的道德教育课程、专门的道德教育机构，但从体现多元主义文化的价值取向、实现社会和谐方面看，其道德教育的效果又是非常显著的。学习、研究加拿大高校的做法，必将有助于我们探索当代高校德育教育模式，提高德育教育的针对性和实效性。'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract3[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ef130e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps = []\n",
    "refs = []\n",
    "for idx in range(len(abstract11_COT)):\n",
    "    hyps.append(' '.join(jieba.cut(abstract13_COT[idx])))\n",
    "    refs.append(' '.join(jieba.cut(Real_outputs[4500+idx])))\n",
    "# hyps = []\n",
    "# refs = []\n",
    "# for idx in idx_list:\n",
    "#     hyps.append(' '.join(jieba.cut(abstract11_COT[idx])))\n",
    "#     refs.append(' '.join(jieba.cut(Real_outputs[4500+idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9fda6de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.3518014805886799,\n",
       "  'p': 0.3563808610743834,\n",
       "  'f': 0.3335740931513661},\n",
       " 'rouge-2': {'r': 0.13909862020290029,\n",
       "  'p': 0.12832937087846863,\n",
       "  'f': 0.12396356451534449},\n",
       " 'rouge-l': {'r': 0.30918160343343565,\n",
       "  'p': 0.24719048924365528,\n",
       "  'f': 0.2539420325819043}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 进行测试，并将测试结果进行输出\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(hyps, refs, avg=True)\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
